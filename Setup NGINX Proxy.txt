Environment Variables


LISTEN_PORT - Port to listen on (default: 8000)

APP_HOST - Hostname of the app to forward requests to (default: app)

APP_PORT - Port of the app to forward requests to (default: 9000)


this is the configuration items that are going to be available for proxy

Listen port the  Port the proxy server listen on 


ECR is same as dockerhub but its aws service can control access with IAM policies

1.create ECR Repository

2.Create an IAM user that's going to be used by gitlab to push proxy image to ECR


use the same name as git lab project name when creating ECR repository

enable scan on push 


create a policy with this permission

{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ecr:*"
            ],
            "Resource": "arn:aws:ecr:us-east-1:*:repository/recipe-app-api-proxy"
        },
        {
            "Effect": "Allow",
            "Action": [
                "ecr:GetAuthorizationToken"
            ],
            "Resource": "*"
        }
    ]
}

Name: RecipeAppApi-ProxyCIPushECR

create IAM user 

receipe-app-api-proxy-ci

programmatic access

ame: RecipeAppApi-ProxyCIPushECR attach this custom policy with user
So the user that has this policy assigned can push to our ECR repository that we created here.


goto Gitlab

setting->CI/CD->variables

variable ->aws_access_key->(add the user here RecipeAppApi-ProxyCIPushECR)->state(protected)only protected use this branch we enabled this in previous
masked(enabled)

same for secret key


variable ->ECR_REPO->(add the URI od ECR reo we created here)->state(protected)only protected use this branch we enabled this in previous
masked(enabled)




We're going to create a feature branch for our change as best practice to never work directly on the

master, the branch.

You always want to create a feature branch or a task branch for the change you want to make this way.

Any changes can be code reviewed and tested by the CI/CD code before that merged into Master.


git checkout -b feature/nginx-proxy

inside the local repo of receipe-app-api-proxy-ci create default.conf.tpl file for nginx

server {
  listen ${LISTEN_PORT};

  location /static {
    alias /vol/static;
  }

  location / {
    uwsgi_pass           ${APP_HOST}:${APP_PORT};
    include              /etc/nginx/uwsgi_params;
    client_max_body_size 10M;
  }
}


Now, the purpose of our engine server is to simply serve the static files and pass the rest of the

request to the running Django application.The reason why Django recommend we do this is because Django and USD  the Python services in general
are not super efficient as serving static data files, static data files or anything like JavaScript

images or CSS, things like that that aren't actually generated by the Python code.

So because it's not super efficient at doing that, we serve it using ngenix, which is super efficient

at serving these types of files.

This helps take a load off our application, so our application only needs to focus on executing the

application code and not actually serving static files.

The way that we do this is we use something called a static URL that is set in Django by default or static

files in Django are prefixed by forward slash static.

We can catch them in our nginx configuration by typing location forward slash static opening the barces


Then we can send Alias to a directory on the proxy server that it will serve the files from.

And what we're going to do later is we're going to map a volume to our running container that contains

all of the static files that Ingenix needs to serve.

what happenes all static content goes to location /static remaining in location /

create a file uwsgi_params

uwsgi_param  QUERY_STRING       $query_string;
uwsgi_param  REQUEST_METHOD     $request_method;
uwsgi_param  CONTENT_TYPE       $content_type;
uwsgi_param  CONTENT_LENGTH     $content_length;

uwsgi_param  REQUEST_URI        $request_uri;
uwsgi_param  PATH_INFO          $document_uri;
uwsgi_param  DOCUMENT_ROOT      $document_root;
uwsgi_param  SERVER_PROTOCOL    $server_protocol;
uwsgi_param  REQUEST_SCHEME     $scheme;
uwsgi_param  HTTPS              $https if_not_empty;

uwsgi_param  REMOTE_ADDR        $remote_addr;
uwsgi_param  REMOTE_PORT        $remote_port;
uwsgi_param  SERVER_PORT        $server_port;
uwsgi_param  SERVER_NAME        $server_name;


paste it here

mving docker image into this folder 


This tells out Unix docker image.

This is a shell script to be executed.

create

entrypoint.sh

#!/bin/sh

set -e

envsubst < /etc/nginx/default.conf.tpl > /etc/nginx/conf.d/default.conf
nginx -g 'daemon off;'


if anything failure return to failure message thats what set -e tells

What this does is it tells Engine X to run with the Dayman off by default.

Engine X runs as a background Damons service.

This way, all of the logs and output from our engine server get printed to the docker output.



BASE IMAGE

Image that Docker starts with and we build on top of -- inorder to create our application

we are not using nginx popular image because that is not a best practice in production that run as a root user


Alpine

Most light weight version of NGINX image

linux os designed for docker container

no unnecessary packages, allows you to add things specific to your application


create 

Dockerfile



FROM nginxinc/nginx-unprivileged:1-alpine
LABEL maintainer="maintainer@londonappdev.com"

COPY ./default.conf.tpl /etc/nginx/default.conf.tpl
COPY ./uwsgi_params /etc/nginx/uwsgi_params

ENV LISTEN_PORT=8000
ENV APP_HOST=app
ENV APP_PORT=9000

USER root

RUN mkdir -p /vol/static
RUN chmod 755 /vol/static
RUN touch /etc/nginx/conf.d/default.conf
RUN chown nginx:nginx /etc/nginx/conf.d/default.conf

COPY ./entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

USER nginx

CMD ["/entrypoint.sh"]



first line to pull nginx alphine image 
next is maintainer

then copy both file from location to nginx location to create docker image

then env variable to pass it to application

then make user root user

and create directory in the path if vol not there that directory also create and inside static and permission and create touch file and nginx user and group

finally switch as ngnix user bash scripting 


.gitlab-ci.yml


image: docker:19.03.5
services:
  - docker:19.03.5-dind

stages:
  - Build
  - Push

Build:
  stage: Build
  before_script: []
  script:
    - mkdir data/
    - docker build --compress -t proxy .
    - docker save --output data/image.tar proxy
  artifacts:
    name: image
    paths:
      - data/

we are running gitlab with docker so we are using docker inside docker thats why  dind
deployment also using docker thats why dind


Artifact is a way you pass file from one job to another 
//build image tagged with proxy




.gitlab-ci.yml

image: docker:19.03.5
services:
  - docker:19.03.5-dind
 
stages:
  - Build
  - Push
 
before_script:
  - apk add python3
  - pip3 install awscli==1.18.8
  - docker load --input data/image.tar
  - $(aws ecr get-login --no-include-email --region us-east-1)
 
Build:
  stage: Build
  before_script: []
  script:
    - mkdir data/
    - docker build --compress -t proxy .
    - docker save --output data/image.tar proxy
  artifacts:
    name: image
    paths:
      - data/
 
Push Dev:
  stage: Push
  script:
    - docker tag proxy:latest $ECR_REPO:dev
    - docker push $ECR_REPO:dev
  rules:
    - if: "$CI_COMMIT_BRANCH == 'main'"
 
Push Release:
  stage: Push
  script:
    - export TAGGED_ECR_REPO=$ECR_REPO:$(echo $CI_COMMIT_TAG | sed 's/-release//')
    - docker tag proxy:latest $TAGGED_ECR_REPO
    - docker push $TAGGED_ECR_REPO
    - docker tag $TAGGED_ECR_REPO $ECR_REPO:latest
    - docker push $ECR_REPO:latest
  rules:
    - if: "$CI_COMMIT_TAG =~ /^*-release$/"



release is going to be done anytime we create a release tag for our project 

The proxy is recommended by the official Django documentation to offload static files to another server, so the Django application can focus on executing Python code.

What can you store using Amazon Elastic Container Registry (ECR)?

ECR is a private docker repository within AWS which is comparable to Docker Hub.



git commit -am ""

git push origin main 


